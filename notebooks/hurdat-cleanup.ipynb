{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data cleaning: HURDAT 2\n",
    "This notebook takes the raw [HURDAT 2](https://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html) data and executes several cleaning operations. The result is a list of observations only for storms that reach hurricane or tropical storm status, and includes the observed storm's code, name, and date of formation in each row."
   ],
   "id": "dd846da413d2c679"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T22:11:45.384092Z",
     "start_time": "2025-11-14T22:11:45.199336Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:11:46.341728Z",
     "start_time": "2025-11-14T22:11:46.337222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def str2deg_lon(s):\n",
    "\t# NOAA longitude recorded as 0 to 360 deg east\n",
    "\tdirection = s[-1]\n",
    "\tdeg = float(s[:-1])\n",
    "\treturn deg if direction == 'E' else 360 - deg\n",
    "\n",
    "def str2deg_lat(s):\n",
    "\t# NOAA latitude recorded as -90 to 90 deg north\n",
    "\tdirection = s[-1]\n",
    "\tdeg = float(s[:-1])\n",
    "\treturn deg if direction == 'N' else -deg"
   ],
   "id": "30abb872ba90e8f9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T22:11:47.438894Z",
     "start_time": "2025-11-14T22:11:47.028772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read in CSV as a Python list\n",
    "with open('../data/raw/hurdat2.csv', mode='r', newline='') as file:\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    orig = list(reader)\n",
    "\n",
    "# strip out whitespace from HTML\n",
    "for i in range(len(orig)):\n",
    "\tfor j in range(len(orig[i])):\n",
    "\t\torig[i][j] = orig[i][j].strip()\n",
    "\n",
    "orig.pop(0) # drop first empty row\n",
    "\n",
    "# Combine section headers into observations, copy only observations to new list\n",
    "lst = []\n",
    "header = []\n",
    "for row in orig:\n",
    "\tif len(row) == 4:\n",
    "\t\theader = row\n",
    "\telse:\n",
    "\t\tlst.append(header + row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_cols = [\n",
    "\t\"code\",\n",
    "\t\"name\",\n",
    "\t\"n_observations\",\n",
    "\t\"UNUSED\",\n",
    "\t\"date_string\",\n",
    "\t\"time_24h\",\n",
    "\t\"record_identifier\",\n",
    "\t\"status\",\n",
    "\t\"lat_string\",\n",
    "\t\"lon_string\",\n",
    "\t\"max_sus_wind_kt\",\n",
    "\t\"min_pressure_mb\",\n",
    "\t\"r_34kt_ne\",\n",
    "\t\"r_34kt_se\",\n",
    "\t\"r_34kt_sw\",\n",
    "\t\"r_34kt_nw\",\n",
    "\t\"r_50kt_ne\",\n",
    "\t\"r_50kt_se\",\n",
    "\t\"r_50kt_sw\",\n",
    "\t\"r_50kt_nw\",\n",
    "\t\"r_64kt_ne\",\n",
    "\t\"r_64kt_se\",\n",
    "\t\"r_64kt_sw\",\n",
    "\t\"r_64kt_nw\",\n",
    "\t\"r_max_sus\"\n",
    "]\n",
    "df = pd.DataFrame(lst, columns=df_cols)\n",
    "\n",
    "# convert datatypes\n",
    "float_cols = [\n",
    "\t\"max_sus_wind_kt\",\n",
    "\t\"min_pressure_mb\",\n",
    "\t\"r_34kt_ne\",\n",
    "\t\"r_34kt_se\",\n",
    "\t\"r_34kt_sw\",\n",
    "\t\"r_34kt_nw\",\n",
    "\t\"r_50kt_ne\",\n",
    "\t\"r_50kt_se\",\n",
    "\t\"r_50kt_sw\",\n",
    "\t\"r_50kt_nw\",\n",
    "\t\"r_64kt_ne\",\n",
    "\t\"r_64kt_se\",\n",
    "\t\"r_64kt_sw\",\n",
    "\t\"r_64kt_nw\",\n",
    "\t\"r_max_sus\"\n",
    "]\n",
    "for col in float_cols:\n",
    "\tdf[col] = df[col].astype('float')\n",
    "\n",
    "# Convert null placeholder values to nan\n",
    "for col in float_cols:\n",
    "\tmask = df[col] < 0\n",
    "\tdf.loc[mask, col] = np.nan\n",
    "\n",
    "# Drop last rows that have no data\n",
    "df = df[~df['status'].isna()]\n",
    "\n",
    "# convert to datetime\n",
    "df['observation_datetime'] = pd.to_datetime(df['date_string']) + pd.to_timedelta(df['time_24h'].astype(int) / 100, unit='h')\n",
    "\n",
    "# add date of formation to every row\n",
    "dates_of_formation = df.groupby('code').agg({'observation_datetime':'min'})\n",
    "dates_of_formation.columns = ['formation_datetime']\n",
    "df = df.merge(right=dates_of_formation, how='left', on='code')\n",
    "\n",
    "# convert lat/lon to NOAA format\n",
    "df['lat'] = df['lat_string'].apply(str2deg_lat)\n",
    "df['lon'] = df['lon_string'].apply(str2deg_lon)\n",
    "\n",
    "# drop all storms that were never tropical\n",
    "# status_mask = df['status'].isin(['HU','TS','TD'])\n",
    "# code_mask = df['code'].isin(df[status_mask].code.unique())\n",
    "# df = df[code_mask]\n",
    "\n",
    "# drop vestigial columns\n",
    "df.drop(axis=1, labels=[\"UNUSED\", \"n_observations\", \"date_string\", \"time_24h\", \"lat_string\", \"lon_string\"], inplace=True)"
   ],
   "id": "21b9249b27a68ce5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.to_csv(\"data/hurdat2_cleaned.csv\", index=False)\n",
    "\n",
    "# Import with:\n",
    "# df = pd.read_csv(\"data/hurdat2_cleaned.csv\", parse_dates=[\"observation_datetime\",\"formation_datetime\"])"
   ],
   "id": "19d656ad6e398b44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
